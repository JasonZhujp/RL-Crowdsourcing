{   # SAC REQUESTER #

    # [common]
    'model_name': 'SAC',
    'for': 'r',
    'seed': 1111,
    'data_dir': "../exp_data/",
    'save_model': True,
    'save_dir': "models/",
    'device': 'cuda',
    'epoch': 5, 
    'train_batch_size': 512,
    'eval_batch_size': 512,
    'eval_frequency': 5,    # 每隔n个batch评估一次
    'save_frequency': 10,   # 每隔n个batch保存一次模型
    'print_frequency': 50,  # 每隔n个batch输出一次中间结果
    'best_info_idx': {
        'category':      0,
        'industry':      1,
        'award':         2,
        'start_gap':     3,
        'end_gap':       4,
        'best_reward_w': 5,
        'best_reward_r': 6
    },
    'info_idx': {
        'legal_max_action':0,
        'category':        1,
        'industry':        2,
        'award':           3,
        'start_gap':       4,
        'end_gap':         5,
        'worker_quality':  6,
        'project_quality': 7
    },
    'sample_num': 2608543,
    'train_award_tolerance_start': 1.0,  # 训练开始时award允许的误差范围
    'train_award_tolerance_end': 0.3,    # 训练结束时award允许的误差范围
    'eval_award_tolerance': 0.3,         # 评估时award允许的误差范围
    'reward_reshape_factor': 0.8,        # 重塑奖励值的比例因子
    'reward_w_factor': 1.0,
    'reward_r_factor_start': 5.0 * 1,    # requester的奖励普遍偏低 开始时设定高
    'reward_r_factor_end': 1.0 * 1,      # requester的奖励普遍偏低 结束时设定低
    'reward_w_factor': 1.0,

    # [wandb]
    'use_wandb': True,
    'wandb_project_name': 'RL_Crowdsourcing',
    'wandb_group_name': 'SAC', 
    'wandb_tags_name': 'r',

    # [network]
    'SACAgent_param': {
        'max_action_num': 83,
        'category_num': 7,
        'category_emb_dim': 4,
        'industry_num': 37,
        'industry_emb_dim': 6,
        'inner_output_dim': 64,
        'nhead_1': 4,
        'nhead_2': 1,
        'encoder_layer_num': 1, 
        'feature_dict': {'category_sec': [0, 6],
                         'industry_sec': [6, 12],
                         'award_sec':    [12, 18],
                         'others_sec':   [18, 24]},
        'a_update_frequency': 2,  # actor的更新频率
        'temperature': 0.15,  # 熵的权重
        'tau': 1e-4,         # 目标网络软更新的比重
        'gamma': 0.9,        # 衰减因子
        'a_lr': 5e-6,
        'q_lr': 5e-5,
        ### actor no scheduler ###
        'a_factor': 0.95,     # 学习率下降的比例
        'q_factor': 0.96,
        'a_patience': 300,   # 能接受多少轮batch没有指标提升
        'q_patience': 320,
        'a_improve':0.03,   # 与最优指标的相对提升阈值
        'q_improve':0.025,
        'device': 'cuda'
    }
}